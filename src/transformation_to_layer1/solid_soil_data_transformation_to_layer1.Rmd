---
title: "solid_soil_data_transformation_to_layer1"
author: "FSCC - ICP Forests"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output: html_document
params:
  # Indicates which code chunks need to be evaluated, to avoid rerunning from start
  breakpoint_recent: "0" # "0", "0_01", "0_02", "1", "1_01", or "2"
---

# Solid soil data: transformation to "layer 1"

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = TRUE) # Set the default eval value for code chunks
knitr::opts_chunk$set(cache = TRUE) # Set the default cache value
```


```{r required_packages_functions, include=FALSE, warning=FALSE, eval=TRUE, cache=FALSE}

# Warning: under Tools > Global Options > R Markdown, make sure that
# "Evaluate chunks in directory" refers to the dropdown option "Project".

stopifnot(require("sf"),
          require("tidyverse"),
          require("openxlsx"),
          require("parsedate"),
          require("googlesheets4"),
          require("googledrive"),
          require("assertthat"))

source("./src/functions/read_raw.R", local = knitr::knit_global())
source("./src/functions/read_processed.R", local = knitr::knit_global())
source("./src/functions/save_to_google_drive.R", local = knitr::knit_global())
source("./src/functions/sync_local_data.R", local = knitr::knit_global())
source("./src/functions/get_date_local.R", local = knitr::knit_global())
source("./src/functions/sync_local_data.R", local = knitr::knit_global())
source("./src/functions/merge_duplicate_records.R",
       local = knitr::knit_global())
source("./src/functions/assign_env.R", local = knitr::knit_global())
source("./src/functions/get_env.R", local = knitr::knit_global())
source("./src/functions/get_primary_inconsistencies.R",
       local = knitr::knit_global())
source("./src/functions/bind_inconsistency_lists.R",
       local = knitr::knit_global())
source("./src/functions/get_coordinate_inconsistencies.R",
       local = knitr::knit_global())
source("./src/functions/get_layer_inconsistencies.R",
       local = knitr::knit_global())
source("./src/functions/get_range_inconsistencies.R",
       local = knitr::knit_global())
source("./src/functions/get_derived_variable_inconsistencies.R",
       local = knitr::knit_global())
source("./src/functions/export_pir.R", local = knitr::knit_global())


```


## Import "layer 0" + add extra columns

* Convert columns with time/date information to a **date** with the function `as.Date()` (in order to allow uniform reporting of the download_date and change_date in PIRs)
* Add column **download_date** with date on which raw "layer 0" data were downloaded from the central PCC database of ICP Forests.
* Add column **layer_type**: factor with levels "forest_floor", "mineral" and "peat"
* Add columns **country**, **partner_short** and **partner** (with the respective country, partner_short and partner names)
* "som" survey forms: column "repetition" becomes 1 for records where "repetition" is NA or -9999
* Add columns with unique identifiers for plots, surveys, repetitions/profile_pit_id's, layers
    + **plot_id**: "partner_code" + "code_plot"
    + **unique_survey**: "partner_code" + "survey_year" + "code_plot"
    + **unique_survey_repetition**: "partner_code" + "survey_year" + "code_plot" + "repetition" ("som" survey forms)
    + **unique_survey_profile**: "partner_code" + "survey_year" + "code_plot" + "profile_pit_id" ("pfh" survey forms)
    + **unique_survey_layer**: "partner_code" + "survey_year" + "code_plot" + "code_layer" ("som" survey forms); or: "partner_code" + "survey_year" + "code_plot" + "horizon_master" ("pfh" survey forms)
    + **unique_layer_repetition**: "partner_code" + "survey_year" + "code_plot" + "code_layer" + "repetition" ("som" survey forms)
* Create a list with harmonised coordinates per survey code.
    + **TO DO: Check with PCC data managers whether coordinates in system installment forms are more likely to be correct than those in solid soil surveys or not.**


* Convert plot codes and coordinates where needed for Poland and the UK

```{r read_raw}
if (params$breakpoint_recent == "0") {

read_raw(code_survey = "y1", save_to_env = TRUE)
read_raw(code_survey = "si", save_to_env = TRUE)
read_raw(code_survey = "s1", save_to_env = TRUE)
read_raw(code_survey = "so", save_to_env = TRUE)
read_raw(code_survey = "sw", save_to_env = TRUE)
}
```

The date on which these "layer 0" data were downloaded from the central ICP Forests database is `r get_date_local(path = "./data/raw_data/", save_to_env = TRUE)`.

## Merge double records in "so_som"

Double records (with the same "unique_layer_repetition" and layer limits) exist for several of the old "so_som" data.
This issue arises from the historical separation of mandatory (SOM) and optional (SOO) parameters during the data reporting.
Some countries reported both the mandatory and optional parameters, while others reported only the primary key and optional parameters.
To address this issue, the function `merged_duplicate_records()` merges such duplicate records, by taking the unique value over the two records per parameter.
In case of conflicts (i.e. different non-NA value in MAN versus OPT for the given parameter), the value in MAN is retained, except for the "other_obs" column, in which the different values are pasted into one string (separated by a semicolon).
This issue has been solved in the past for "s1_som" in the central database. **TO DO: double-check the assumption that this merging happened correctly for s1**

* Add column **origin_merged**: logical which indicates rows which were merged from one "MAN" and one "OPT" record.
* Add column **origin_merge_info**: character string which gives information on the reduction in the amount of rows at the level of the whole survey form (so_som).

```{r merge_duplicate_records}
if (params$breakpoint_recent == "0") {

merge_duplicate_records("so_som",
                        merge = TRUE,
                        save_to_env = TRUE)

}
```

This way, the "so_som" dataframe is reduced from `r extract_merge_info(survey_form = "so_som")[1]` to `r extract_merge_info(survey_form = "so_som")[2]` rows, with records removed (after merging their information to their respective other records) from survey years between `r extract_merge_info(survey_form = "so_som")[3]` and `r extract_merge_info(survey_form = "so_som")[4]`.


## Harmonise code_layer with layer limits in "som" survey forms + get primary key inconsistencies

* "s1_som" and "so_som" survey forms: If there are non-unique primary keys (duplicated unique_layer_repetition) because of records with the same "code_layer" + different layer limits or NA layer limits + the same "origin" or no "origin" column; within a given profile (repetition).
    + copy the column "code_layer" to a new column **code_layer_original**
    + change the **code_layer** column for these ambiguous layers to [first letter, i.e. "M" or "H"] + [layer_limit_superior] + [layer_limit_inferior], e.g. "M5060", "M8590" etc 
    + update unique identifiers that include "code_layer"
  This happened for:
    + 10 plots for which this issue already existed in the past (Sweden, Finland, Estonia - due to multiple "M48", "Mxx" or "Hxx" layers): "13_731", "13_1360", "13_1607", "13_1608", "13_2515", "13_2529", "13_2737", "13_3768", "15_1620", "59_43"

Note: this is only a solution for internal use to avoid conflicts in primary key. This problem arises from not following the manual correctly, since fixed layers should not display pedogenic horizons (even in case of alternating peat and mineral layers).

```{r get_primary_inconsistencies}
if (params$breakpoint_recent == "0") {

get_primary_inconsistencies("y1", save_to_env = TRUE)
get_primary_inconsistencies("si", save_to_env = TRUE)
get_primary_inconsistencies("s1", solve = TRUE, save_to_env = TRUE)
get_primary_inconsistencies("so", solve = TRUE, save_to_env = TRUE)
get_primary_inconsistencies("sw", save_to_env = TRUE)
bind_inconsistency_lists("list_primary_inconsistencies", save_to_env = TRUE)

}
```

## Create a list with coordinate inconsistencies

* Remove columns "latitude_error" and "longitude_error"

```{r get_coordinate_inconsistencies}
if (params$breakpoint_recent == "0") {
get_coordinate_inconsistencies(surveys_with_coordinates = NULL,
                               boundary_buffer_meter = 3000,
                               save_to_env = TRUE)
}
```


## Harmonise layers/horizons and their depth limits

* "som" survey forms: Update "layer_limit_superior" and "layer_limit_inferior":
    + Copy the column "layer_limit_superior" to a new column "layer_limit_superior_orig" + the column "layer_limit_inferior" to a new column "layer_limit_inferior_orig"
    + Update the columns "layer_limit_superior" and "layer_limit_inferior":
        + Multiply records with wrong signs of above-ground or below-ground layers [see PIR for rule_id = "FSCC_2"] with a factor *(-1)
        + Empty layer limits which are clearly a mistake: where layer limits equal 0 for multiple depth layers within a profile [see PIR for rule_id = "FSCC_9"]
        + Empty layer limits which are clearly a mistake: where superior layer limit equals inferior layer limit [see PIR for rule_id = "FSCC_11"]
        + Empty layer limits which are clearly a mistake: where layer limits equal -9999 [see PIR for rule_id = "FSCC_51"]
    + Gap-fill empty layer_limit_superiors and layer_limit_inferiors
        + Retrieve the layer limits from the corresponding "pfh" survey forms if possible (based on an equal "code_layer", so only for forest floor layers)
        + Fill these layer limits based on the theoretical layer limits ("d_depth_level_soil": add columns with theoretical superior and inferior layer limits based on the column "description" in "d_depth_level_soil")
* "pfh" survey forms: Update "horizon_limit_up" and "horizon_limit_low":
    + Copy the column "horizon_limit_up" to a new column "horizon_limit_up_orig" + the column "horizon_limit_low" to a new column "horizon_limit_low_orig"
    + Update the columns "horizon_limit_up" and "horizon_limit_low":
        + Multiply records with wrong signs of above-ground or below-ground layers [see PIR for rule_id = "FSCC_2"] with *(-1)
* Create a column "layer_number" (in "som" survey forms) or "horizon_number_unique" (in "pfh" survey forms) which represents the rank of a layer (from top to bottom) within a profile (unique "repetition" or "profile_pit_id"). So-called redundant layers (i.e. layers which cover the same depths like other layers from the same profile and which can therefore be "left out" without any effect on the depths which are covered by the data of the given profile) are not included in this ranking . If there are multiple parallel options when identifying these redundant layers (e.g. "M01" versus "M05" + "M51"): consider the least "detailed" layer(s) (i.e. layer(s) with largest depth range) as redundant (i.e. "M01" in the given example). In general, ranking happens based on the superior/upper and inferior/lower layer limits.
    + "pfh" survey forms: for profiles without any redundant layers: "horizon_number_unique" equals "horizon_number" if the ranking of "horizon_number" equals the ranking of the layer limits (which is not always the case); else "horizon_number_unique" is based on the ranking of the layer limits.
    + "som" survey forms: Include forest floor without layer limits in the ranking. The following table shows how the forest floor layer combinations are ranked (based on theoretical sequence of forest floor layers, e.g. "OL" on top etc + analysis of the total organic carbon content of the existing forest floor combinations):  

**TO DO: ADD SOURCE OF ESTIMATED LAYER LIMITS**

**Two forest floor layers**  

Superior (1)    | Inferior (2) 
--------------- | --------------- 
O2              | O
O (3204)        | O2 (3204)
O               | O1 
O1              | O2
OF              | OH 
OL              | OF 
OL              | OFH 
OL              | OH 
OLF             | OH  

**Three forest floor layers**  

Superior (1) | Middle (2)  | Inferior (3)
-------------|-------------|-------------
OL           | OF          | OH  
O            | O3          | O2

Special case: one Latvian profile (plot_id 64_5; survey year 2004) contains two records without code_layer, layer_limits, and with only one organic_carbon_total value.
Assumption: since the remaining records from the same profile are M01, M12, M24, M48, and since organic_layer_weight is reported, it is plausible to assume that these are forest floor layers.
Because of the organic_layer_weight information, these records are valuable for C stock calculations. In order to assess which of the records was on top and which was below, we can base ourselves on organic_layer_weight information. Analysis of the organic_layer_weight in so_som profiles with at least two forest floor layers teaches us that it is most likely that the inferior layer usually has a higher organic_layer_weight than the superior layer.
Action: rename code_layer of these records so that the right layer number will be assigned in accordance with the assumptions above.

* Create columns "layer_number_bg" and "layer_number_ff" (in "som" survey forms) or "horizon_number_bg" and "horizon_number_ff" (in "pfh" survey forms) which represents the rank of a layer (from top to bottom) within a profile (unique "repetition" or "profile_pit_id"), but only for below-ground (peat and mineral layers) versus above-ground layers, respectively. This is based on the column "layer_number" ("som" survey forms) or "horizon_number_unique" ("pfh" survey forms).
* Sort the rows based on (i) partner_code; (ii) unique_survey_repetition / unique_survey_profile; and (iii) layer_number / horizon_number_unique.


```{r get_layer_inconsistencies}
if (params$breakpoint_recent == "0") {

get_layer_inconsistencies("so_som", solve = TRUE, save_to_env = TRUE)
get_layer_inconsistencies("s1_som", solve = TRUE, save_to_env = TRUE)
get_layer_inconsistencies("so_pfh", solve = TRUE, save_to_env = TRUE)
get_layer_inconsistencies("s1_pfh", solve = TRUE, save_to_env = TRUE)
bind_inconsistency_lists("list_layer_inconsistencies", save_to_env = TRUE)

}
```



## Correct obvious mistakes regarding data ranges

* Convert data that are reported in the wrong parameter units to the right parameter units [see PIR for rule_id = "FSCC_22"] by multiplying with a factor * 10 (% to g kg-1 for "organic_carbon_total", "n_total", "horizon_c_organic_total", "horizon_n_total", "horizon_caco3_total", "horizon_gypsum") or with a factor * 1000 (g cm-3 to kg m-3 for "bulk_density", "horizon_bulk_dens_measure", "horizon_bulk_dens_est")

**TO DO: add organic_layer_weight (see Slovakia 2009)**
**TO DO: wrong units 3604_1995**

```{r get_range_inconsistencies}
if (params$breakpoint_recent == "0") {

get_range_inconsistencies("s1_som", solve = TRUE, save_to_env = TRUE)
get_range_inconsistencies("s1_pfh", solve = TRUE, save_to_env = TRUE)
get_range_inconsistencies("so_som", solve = TRUE, save_to_env = TRUE)
get_range_inconsistencies("so_pfh", solve = TRUE, save_to_env = TRUE)
get_range_inconsistencies("sw_swc", solve = TRUE, save_to_env = TRUE)
get_range_inconsistencies("so_prf", save_to_env = TRUE)
get_range_inconsistencies("s1_prf", save_to_env = TRUE)
get_range_inconsistencies("so_pls", save_to_env = TRUE)
get_range_inconsistencies("s1_pls", save_to_env = TRUE)
get_range_inconsistencies("si_sta", save_to_env = TRUE)
get_range_inconsistencies("y1_st1", save_to_env = TRUE)
bind_inconsistency_lists("list_range_inconsistencies", save_to_env = TRUE)

}
```



## Add derived variables

* "som" survey forms: Add columns with the following processed data:
    + "layer_thickness": difference between "layer_limit_superior" and "layer_limit_inferior" (where required data are available)
    + "bulk_density_layer_weight": "organic_layer_weight" / "layer_thickness" (where required data are available)
    + "sum_texture": "part_size_clay" + "part_size_silt" + "part_size_sand" (where required data are available). Data below the LOQ (i.e. -1) are replaced by half of the LOQ (i.e. by 0.5).
    + "c_to_n_ratio": "organic_carbon_total" / "n_total" (where required data are available and not lower than the LOQ, i.e. not equal to -1)
    + "sum_base_cations": "exch_ca" + "exch_mg" + "exch_k" + "exch_na" (where required data are available and where at least two of the parameters are not below the LOQ, i.e. not equal to -1). Data below the LOQ (i.e. -1) are replaced by half of the LOQ (i.e. by 0.015).
    + "sum_acid_cations": "exch_al" + "exch_fe" + "exch_mn" + "free_h" (where required data are available and where at least two of the parameters are not below the LOQ, i.e. not equal to -1). Data below the LOQ (i.e. -1) are replaced by half of the LOQ (i.e. by 0.01 for "exch_al", "exch_fe", "exch_mn" and by 0.05 for "free_h")
* "pfh" survey forms: Add columns with the following processed data:
    + "sum_texture": "horizon_clay" + "horizon_silt" + "horizon_sand" (where required data are available). Data below the LOQ (i.e. -1) are replaced by half of the LOQ (i.e. by 0.5).
    + "c_to_n_ratio": "horizon_c_organic_total" / "horizon_n_total" (where required data are available and not lower than the LOQ, i.e. not equal to -1)
    + "sum_base_cations": "horizon_exch_ca" + "horizon_exch_mg" + "horizon_exch_k" + "horizon_exch_na" (where required data are available and where at least two of the parameters are not below the LOQ, i.e. not equal to -1). Data below the LOQ (i.e. -1) are replaced by half of the LOQ (i.e. by 0.015).

```{r get_derived_variable_inconsistencies}
if (params$breakpoint_recent == "0") {

get_derived_variable_inconsistencies("so_som", save_to_env = TRUE)
get_derived_variable_inconsistencies("so_pfh", save_to_env = TRUE)
get_derived_variable_inconsistencies("s1_som", save_to_env = TRUE)
get_derived_variable_inconsistencies("s1_pfh", save_to_env = TRUE)
bind_inconsistency_lists("list_derived_inconsistencies", save_to_env = TRUE)

}
```


## BREAKPOINT 0_01

```{r save_to_google_drive}
if (params$breakpoint_recent == "0") {
save_to_google_drive(path_name = "0_01")
}
```

```{r breakpoint_0_01, eval=FALSE}
if (params$breakpoint_recent == "0_01") {
sync_local_data()
read_processed(save_to_env = TRUE)
}
```


## TO DO

* Gap-filling:
    + Folder with direct partner communication (AFSCDB.LII.2.1 subfolder) - at least Austria, Spain, bulk density and coarse fragments from Sweden...
    + Folder AFSCDB.LII.2.2
    + Folder BIOSOIL.LII - at least Spain, Finland...
    + Anything to gap-fill for LI? (e.g. folders BIOSOIL.LI, FSCDB.LI.1?) FSCDB.LI.1: check whether any "OPT" data are currently missing. Oldest survey from Italy seems to be missing, Latvia and Austria probably incomplete too?
    + PIRs (note separate e-mail Sture Wijk; Czech pH-H2O in "pfh") + add column with validation code different parameters?
    + Add column with data source
    + Harmonise layers with custom depths (e.g. Mxx, Hxx, often in profiles with
    both peat and mineral) to theoretical fixed depths using C content and bulk
    density where needed, e.g. Estonia
    + Check whether harmonisation of layer limits is needed, i.e. negative for
    forest floor layers (e.g. Estonia)
    + Note that some of the fixed-depth profiles do contain gaps, i.e.
    impossible to harmonise (except through mass-preserving splines?)
* Check "other_obs" columns
* Harmonise plot_id's and coordinates (e.g. Poland, UK)
* Coordinate issue in Pyrennees Spain?
* Harmonise "horizon_coarse_weight" if volumetric instead of wt% (e.g. Slovak
Republic)
* Harmonise soil texture where needed (e.g. Wallonia) to 63 µm using R soil texture wizard)
* "so_prf" (+ when possible: "s1_prf"): Join dataframe with harmonised WRB soil classification information by Nathalie
    + Include column with harmonisation method
    + Include column with qualitative eutric/dystric factor
    + Recode humus type (e.g. amphihumus) in accordance with survey year
    + After joining: identify missing plots without soil classification (due to gap-filling) - also check in other survey forms.
    + s1_prf: create machine-learning model to predict WRB soil classes in plots where this information is lacking?
    prf: één record per profiel?
* Check Russian plots in "so" survey: some of them actually belong to "s1". Move accordingly.
* Germany: harmonisation partner code in different survey forms?
* LOQ: harmonise and list assumptions
* Ring tests
* Gap-filling forest types and WRB LI and humus + confirmation by national experts?
* Remove incomplete unique profiles (e.g. profiles with only one forest floor layer)? Or do we keep it for plot-level integration (at least in "som" forms, i.e. with fixed depths)



# Additional tests future PIRs

**TO DO**
* Should an OL layer always be present in theory? Or depending on season, forest type?
* When no O layers are reported: are they actually not present or have they just been ignored in the survey?
* Check whether plots in other survey forms are also reported in "pls"
* Check for values below LOQ (should be -1)
* Add a plausible range test for organic_layer_weight
* Histosol: are H layers reported in "som"?
* Are % OC values below 20 % in M layers and above 20 % in H layers?
* When NA is reported for coarse fragments: is this actually not measured or does this mean that there are no stones?
* Check whether code_plots are unique linked with coordinates.


# Transformation layer 1 --> layer 2

**TO DO**

* Harmonisation of "som" survey forms to uniform layers: e.g. to ("OL", "OFH",) "M01", "M12", "M24"... 
* Summarise over different replicate profiles ("repetition" or "profile_pit_id") per survey per plot (for each layer): average and standard deviation? (only for "som" survey forms)
* "prf" and "pfh" files: retain one observation over time (data in these survey forms are assumed to be constant)
* Selection of "useful" plots to be retained for further processing?

# Stocks, indicators

**TO DO**
* Gap-filling possibilities + list assumptions (see presentation Bruno Vienna)
* Machine-learning prediction of lowest point splines + Monte Carlo uncertainty?
* FSCDB.LI: Check whether indicator data in VWDD tables match the Vanmechelen report formulas
* Check within-plot variability


